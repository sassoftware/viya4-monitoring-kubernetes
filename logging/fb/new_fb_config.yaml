service:
  flush: 1
  daemon: off
  log_level: info
  parsers_file: parsers.conf
  parsers_file: viya-parsers.conf
  http_server: on
  http_listen: 0.0.0.0
  http_port: 2020
  storage.path: /var/log/v4m-fb-storage
  storage.checksum: off
  storage.sync: normal
  storage.backlog.mem_limit: 5m
  storage.metrics: on

  pipeline:
    inputs: 
      name: tail
      alias: tail4logs
      path: /var/log/containers/*.log
      exclude_path: /var/log/containers/v4m-*.log
      parser: ${kubernetes_runtime_logfmt}
      tag: kube.*
      multiline.parser: ${log_multiline_parser}
      refresh_interval: 5
      mem_buf_limit: 5mb
      skip_long_lines: on
      read_from_head: on
      ignore_older: 1d
      db: /var/log/v4m-fb-storage/v4m_fb.db
      db.locking: on
      storage.type: filesystem

      processors:
        logs:
          - name: modify
            set: 
              - fb_configMap_version 0.3.00
              #- set: clusterID NOT_SET
              #initialized to N to force level standardization
              - __temp_level_fixed   N
          - name: kubernetes
            kube_tag_prefix: kube.var.log.containers.
            kube_url: https://kubernetes.default.svc:443
            kube_ca_file:  /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            kube_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            buffer_size: 128kb
            cache_use_docker_id: on
            merge_log: on
            merge_log_key: json_log
            k8s-logging.parser: on
            k8s-logging.exclude: on

    outputs:
      name:  opensearch
      alias: opensearch_logs
      host: ${SEARCH_SERVICENAME}
      port:  9200
      buffer_Size: 512KB
      logstash_format: on
      retry_limit: 5
      suppress_type_name: on
      workers: 2
      time_key: @timestamp
      generate_id:  on
      replace_dots: on
      logstash_prefix: viya_logs
      http_user: ${ES_LOGCOLLECTOR_USER}
      http_passwd: ${ES_LOGCOLLECTOR_PASSWD}
      tls: on
      tls.debug: 2
      tls.verify: off
